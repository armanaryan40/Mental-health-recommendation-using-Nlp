{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1503731486ad447aad818bcfce2f9f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f83c81b821424328b4985d3ee56c2a1e",
              "IPY_MODEL_6a60f039478c46e6ac15b2f6841bad66",
              "IPY_MODEL_120dc89d1bd44596b8948fc199122f59"
            ],
            "layout": "IPY_MODEL_cd4361fdf90748d49c0294b65b672f8f"
          }
        },
        "f83c81b821424328b4985d3ee56c2a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228f542ecc0149fa99d13a25c933ecfc",
            "placeholder": "​",
            "style": "IPY_MODEL_367549f9315443babb85e13f55df98bf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "6a60f039478c46e6ac15b2f6841bad66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b0389e4eec649369f34c4346fb38102",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db929e5d6d4e4b41a56b558f1bca2809",
            "value": 48
          }
        },
        "120dc89d1bd44596b8948fc199122f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_325fdf865369439ea03d97f1b2edb2bd",
            "placeholder": "​",
            "style": "IPY_MODEL_b88ff76de8ba48f791d816275b14f811",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.09kB/s]"
          }
        },
        "cd4361fdf90748d49c0294b65b672f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228f542ecc0149fa99d13a25c933ecfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "367549f9315443babb85e13f55df98bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b0389e4eec649369f34c4346fb38102": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db929e5d6d4e4b41a56b558f1bca2809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "325fdf865369439ea03d97f1b2edb2bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b88ff76de8ba48f791d816275b14f811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5babb6add5c14a97aea2db33258d62a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66e32fd496684d2e88ba0d9673f5c42a",
              "IPY_MODEL_bc73e5e739a749ee90bb01e73c9f4a23",
              "IPY_MODEL_b86b95d5308b41b5b404db002ca1ba74"
            ],
            "layout": "IPY_MODEL_820ed39bdc26444bbff5ed418f905848"
          }
        },
        "66e32fd496684d2e88ba0d9673f5c42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5a2925490124d4dab752353dbb59561",
            "placeholder": "​",
            "style": "IPY_MODEL_10f9b094166d4f66a0fccb3afca2bcf9",
            "value": "vocab.txt: 100%"
          }
        },
        "bc73e5e739a749ee90bb01e73c9f4a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675536c9214b478f813cfe653c59aa16",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff97af07bd3649a8bf28e27a7a90ae13",
            "value": 231508
          }
        },
        "b86b95d5308b41b5b404db002ca1ba74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_485fd7265b03432dbaa568cfd1e2f6d2",
            "placeholder": "​",
            "style": "IPY_MODEL_9a986585bd1049e18f3b8abf8f980387",
            "value": " 232k/232k [00:00&lt;00:00, 3.46MB/s]"
          }
        },
        "820ed39bdc26444bbff5ed418f905848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a2925490124d4dab752353dbb59561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f9b094166d4f66a0fccb3afca2bcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675536c9214b478f813cfe653c59aa16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff97af07bd3649a8bf28e27a7a90ae13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "485fd7265b03432dbaa568cfd1e2f6d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a986585bd1049e18f3b8abf8f980387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b7e42d8e8ef4f508b3d3577c18a157e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f76726fc81d44e1bac1c2dc476d369a6",
              "IPY_MODEL_1b6cc79106d548e08c67f2ec7a58418e",
              "IPY_MODEL_166f285b921d41d99e802e60c2196efb"
            ],
            "layout": "IPY_MODEL_bd331553b91f4a6995a09c1713e5e841"
          }
        },
        "f76726fc81d44e1bac1c2dc476d369a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c49f6f5e0054e2b94e4d984874af284",
            "placeholder": "​",
            "style": "IPY_MODEL_3f08e1220f92441b9fcbaef5e967ab1b",
            "value": "tokenizer.json: 100%"
          }
        },
        "1b6cc79106d548e08c67f2ec7a58418e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2241ccaa2f4c4da2ada33bbd84bf8a2f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1bc3facf77147e0b66f844e11312b20",
            "value": 466062
          }
        },
        "166f285b921d41d99e802e60c2196efb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a260d900ef54db1878fb5a131f5a9bc",
            "placeholder": "​",
            "style": "IPY_MODEL_368d13e1ad2f4fc485e97d46383485d8",
            "value": " 466k/466k [00:00&lt;00:00, 14.1MB/s]"
          }
        },
        "bd331553b91f4a6995a09c1713e5e841": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c49f6f5e0054e2b94e4d984874af284": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f08e1220f92441b9fcbaef5e967ab1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2241ccaa2f4c4da2ada33bbd84bf8a2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1bc3facf77147e0b66f844e11312b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a260d900ef54db1878fb5a131f5a9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "368d13e1ad2f4fc485e97d46383485d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18daf77dd72e45d9a1b019924a84280c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_592187af9dfb4e75a5573dcd62f4c707",
              "IPY_MODEL_dc0b099cf67443e2b55ec5beae3a2bc8",
              "IPY_MODEL_795c4aaa8ad14323b7d2171387d3312f"
            ],
            "layout": "IPY_MODEL_dd923a002e75454bab960e945c7bfdbb"
          }
        },
        "592187af9dfb4e75a5573dcd62f4c707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b23237207044cc5bda7a84d0492593a",
            "placeholder": "​",
            "style": "IPY_MODEL_359881f863f04b52b2ce9689d856f50f",
            "value": "config.json: 100%"
          }
        },
        "dc0b099cf67443e2b55ec5beae3a2bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e5ffdeb4bd64d5d86c35920cb5b9a85",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eece52f0f1f74741900817a3ae6df0a6",
            "value": 570
          }
        },
        "795c4aaa8ad14323b7d2171387d3312f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_048623baa20c4c1483cd2771061e0398",
            "placeholder": "​",
            "style": "IPY_MODEL_1989f05c35a341ec9c1af5dd9031559f",
            "value": " 570/570 [00:00&lt;00:00, 15.8kB/s]"
          }
        },
        "dd923a002e75454bab960e945c7bfdbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b23237207044cc5bda7a84d0492593a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "359881f863f04b52b2ce9689d856f50f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e5ffdeb4bd64d5d86c35920cb5b9a85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eece52f0f1f74741900817a3ae6df0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "048623baa20c4c1483cd2771061e0398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1989f05c35a341ec9c1af5dd9031559f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "355039680b53439faf9161bee31dfc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1fba630d0be747aabc03329c6627026a",
              "IPY_MODEL_2002bfd68a28428ab71544d987d36e2b",
              "IPY_MODEL_bc4fdf8aebf14780b3645a5e82b02f15"
            ],
            "layout": "IPY_MODEL_f0fd5c0fb0ec4ed08fc952311b1dacc4"
          }
        },
        "1fba630d0be747aabc03329c6627026a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_228a59c42c62405c80db8ea076de4b66",
            "placeholder": "​",
            "style": "IPY_MODEL_02f35f8298b54290b7a0840ac8ca7bd0",
            "value": "model.safetensors: 100%"
          }
        },
        "2002bfd68a28428ab71544d987d36e2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bbfbcaca114dae94202bc01a2e43bd",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d3301358f054f3896a69cc00ca45eef",
            "value": 440449768
          }
        },
        "bc4fdf8aebf14780b3645a5e82b02f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09f4d3feb2d04bbba1d4704c03346184",
            "placeholder": "​",
            "style": "IPY_MODEL_9ac425f6dd5444788c4ced7529712e86",
            "value": " 440M/440M [00:02&lt;00:00, 189MB/s]"
          }
        },
        "f0fd5c0fb0ec4ed08fc952311b1dacc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "228a59c42c62405c80db8ea076de4b66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f35f8298b54290b7a0840ac8ca7bd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49bbfbcaca114dae94202bc01a2e43bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d3301358f054f3896a69cc00ca45eef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09f4d3feb2d04bbba1d4704c03346184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac425f6dd5444788c4ced7529712e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What are Transformers?\n",
        "\n",
        "\n",
        "https://www.youtube.com/watch?v=4Bdc55j80l8&t=414s&pp=ygUYdHJhbnNmb3JtZXIgYXJjaGl0ZWN0dXJl"
      ],
      "metadata": {
        "id": "WouX9M4jnOtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **1. Transformer Architecture: Encoder and Decoder**\n",
        "\n",
        "The **Transformer architecture**, introduced in the paper \"***Attention is All You Need***\" by Vaswani et al. (2017), marked a significant breakthrough in natural language processing (NLP). Unlike traditional RNNs, which process sequences word-by-word, the Transformer processes all tokens in parallel, using a mechanism called **Self-Attention**.\n",
        "\n",
        "### **1.1. High-Level Architecture**\n",
        "- The Transformer consists of **two main components**:\n",
        "  1. **Encoder**: Processes the input text and learns its representation.\n",
        "  2. **Decoder**: Uses the encoded representation to generate the output text.\n",
        "\n",
        "Each component is made up of **layers**, and the original Transformer uses **6 layers** for both the Encoder and the Decoder. Let’s break down these parts in detail:\n",
        "\n",
        "---\n",
        "\n",
        "### **1.2. Encoder Component**\n",
        "\n",
        "The **Encoder** is responsible for reading the input sequence and converting it into a high-dimensional representation that captures the relationships and meanings of the words.\n",
        "\n",
        "#### **Structure of the Encoder**\n",
        "Each **Encoder layer** consists of:\n",
        "1. **Self-Attention Mechanism**\n",
        "2. **Feed-Forward Neural Network**\n",
        "3. **Layer Normalization**\n",
        "4. **Residual Connections**\n",
        "\n",
        "**1.2.1. Self-Attention Mechanism**\n",
        "- **Self-Attention** allows each word in the input sequence to focus on other words to understand their relationships.\n",
        "- For example, in the sentence **\"The cat chased the mouse,\"** the word **\"cat\"** can learn that **\"chased\"** and **\"mouse\"** are related to it, even though they are not immediately next to it.\n",
        "  \n",
        "**How Self-Attention Works**:\n",
        "- **Step 1: Create Queries, Keys, and Values**:\n",
        "  - Every word in the input sequence is transformed into **three vectors**: a **Query (Q), Key (K),** and **Value (V)**.\n",
        "  - These vectors are created by multiplying the input embeddings with weight matrices.\n",
        "  - The idea is that the **Query** represents the current word, **Keys** represent all other words, and **Values** hold the information from those words.\n",
        "- **Step 2: Calculate Attention Scores**:\n",
        "  - The attention score for a word is calculated as the **dot product** of the Query vector of the word with the Key vectors of all other words. This tells the model how much focus the current word should give to other words.\n",
        "  - The higher the dot product, the more attention that word gets. For instance, **\"cat\"** might have high scores for **\"chased\"** and **\"mouse.\"**\n",
        "- **Step 3: Softmax and Weight the Values**:\n",
        "  - Apply **softmax** to convert scores into probabilities (attention weights), ensuring they sum to 1.\n",
        "  - Multiply each Value vector by its attention weight to produce the final output. This allows the model to aggregate information from relevant words.\n",
        "\n",
        "**1.2.2. Multi-Head Attention**\n",
        "- **Multi-Head Attention** means the self-attention mechanism is run **multiple times** in parallel, each time with different learned weight matrices.\n",
        "- This allows the model to focus on **different aspects of relationships** (e.g., subject-object relationships, verb tense, etc.). The results from all heads are combined, enabling the model to capture a richer set of features.\n",
        "\n",
        "**1.2.3. Feed-Forward Neural Network (FFN)**\n",
        "- After self-attention, the output is passed through a **Feed-Forward Neural Network**.\n",
        "- This is a simple fully connected network applied independently to each position, introducing non-linearity and learning more complex patterns.\n",
        "\n",
        "**1.2.4. Layer Normalization and Residual Connections**\n",
        "- **Layer Normalization** is applied after each sub-layer (Self-Attention and FFN) to stabilize the training process.\n",
        "- **Residual Connections** are added to enable the model to learn faster by ensuring that gradient signals do not vanish. This means the output of each sub-layer is added to its input before passing it to the next sub-layer.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.3. Positional Encoding**\n",
        "- Since Transformers process all words simultaneously, they need a way to understand the **order** of words (e.g., \"dog bites man\" vs. \"man bites dog\").\n",
        "- **Positional Encoding** adds information about each word’s position in the sequence. This encoding is added to the input embeddings, enabling the model to understand which word comes first, second, and so on.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.4. Decoder Component**\n",
        "\n",
        "The **Decoder** is responsible for generating the output sequence based on the information provided by the Encoder.\n",
        "\n",
        "#### **Structure of the Decoder**\n",
        "Each **Decoder layer** consists of:\n",
        "1. **Masked Self-Attention**\n",
        "2. **Encoder-Decoder Attention**\n",
        "3. **Feed-Forward Neural Network**\n",
        "4. **Layer Normalization**\n",
        "5. **Residual Connections**\n",
        "\n",
        "**1.4.1. Masked Self-Attention**\n",
        "- **Masked Self-Attention** ensures that while generating a word, the Decoder can only look at **previously generated words** and not future ones. This is achieved by masking out future words during the training phase.\n",
        "\n",
        "**1.4.2. Encoder-Decoder Attention**\n",
        "- **Encoder-Decoder Attention** allows the Decoder to focus on relevant parts of the input sequence (from the Encoder). It is similar to the Encoder’s self-attention, but it uses the **output of the Encoder** as Keys and Values and the Decoder’s input as Queries.\n",
        "- For example, while generating the word **\"ran\"** in the output, the model can attend to **\"dog\"** and **\"park\"** in the input, ensuring it understands that **\"dog ran to the park.\"**\n",
        "\n",
        "**1.4.3. Feed-Forward Neural Network (FFN)**\n",
        "- Like the Encoder, each Decoder layer has a Feed-Forward Neural Network that learns complex transformations.\n",
        "\n",
        "---\n",
        "\n",
        "### **1.5. Putting It All Together**\n",
        "The Transformer architecture can be summarized as:\n",
        "- **Encoder**: Reads the entire input sequence and transforms it into a representation that captures the relationships between words using Self-Attention and FFNs.\n",
        "- **Decoder**: Uses the encoded representation and **masked** self-attention to generate the output sequence one word at a time, focusing on relevant parts of the input as needed.\n",
        "\n",
        "### **Key Strengths of Transformers**\n",
        "1. **Parallel Processing**: Unlike RNNs, Transformers can process all words in a sequence simultaneously, leading to faster training times.\n",
        "2. **Global Context**: Self-Attention allows the model to understand relationships between words, regardless of how far apart they are, enabling it to capture more nuanced patterns in language.\n",
        "3. **Scalability**: Because Transformers can be parallelized, they scale efficiently, allowing models to be trained on massive datasets.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Jsvh3p--nW2y"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JyC6hQ39nbL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT Architecture"
      ],
      "metadata": {
        "id": "RMAXMqu3nuAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. BERT: Bidirectional Encoder Representations from Transformers**\n",
        "\n",
        "**BERT** is a model introduced by Google in 2018, and it is one of the most popular Transformer-based models used for a wide range of NLP tasks, including **question answering, sentiment analysis, and named entity recognition**. Unlike the original Transformer architecture, which has both an Encoder and a Decoder, **BERT uses only the Encoder** part of the Transformer.\n",
        "\n",
        "### **2.1 What Makes BERT Unique?**\n",
        "1. **Bidirectional Context Understanding**:\n",
        "   - Traditional models, including early Transformer-based models, often read text in a left-to-right or right-to-left manner. This means they understand each word by considering only the preceding or succeeding words.\n",
        "   - **BERT is bidirectional**, meaning it reads the entire sequence of words simultaneously and understands each word based on its **full context**. This allows BERT to capture richer relationships between words because it considers **both** the words before and after a given word.\n",
        "\n",
        "2. **Pre-Training and Fine-Tuning**:\n",
        "   - **Pre-Training**: BERT is pre-trained on massive datasets (like Wikipedia and BooksCorpus) using two tasks:\n",
        "     1. **Masked Language Modeling (MLM)**: BERT randomly masks (hides) some words in the input sentence and learns to predict those masked words based on the surrounding words. For example, in **\"The cat sat on the [MASK],\"** BERT would learn to predict **\"mat.\"** This helps it understand context.\n",
        "     2. **Next Sentence Prediction (NSP)**: BERT also learns the relationship between two sentences by predicting if the second sentence logically follows the first. This helps in tasks that require understanding the connection between sentences, like **question answering.**\n",
        "   - **Fine-Tuning**: After pre-training, BERT can be fine-tuned on specific tasks. This means it can be adapted to perform tasks like sentiment analysis, text classification, or question answering with just a small amount of task-specific data.\n",
        "\n",
        "### **2.2 BERT Architecture**\n",
        "BERT uses the **Encoder** part of the Transformer architecture, which we've already discussed. However, it has some specifics:\n",
        "\n",
        "1. **Multiple Encoder Layers**:\n",
        "   - The original BERT model has **12 layers** (BERT-Base) or **24 layers** (BERT-Large) of Encoders. Each layer is essentially the same as what we described earlier, with **Self-Attention** and **Feed-Forward Neural Networks.**\n",
        "   - Each layer can process the entire input sequence simultaneously, and each word can attend to every other word using Self-Attention.\n",
        "\n",
        "2. **Positional Embeddings**:\n",
        "   - Since BERT does not process input sequentially, it needs **Positional Embeddings** to know the order of words. These embeddings are added to the input word embeddings to provide information about the position of each word in the sentence.\n",
        "\n",
        "3. **Input Representations in BERT**:\n",
        "   - BERT’s input representation is **very detailed**. Each input consists of three embeddings:\n",
        "     1. **Token Embeddings**: The standard word embeddings (like we see in Word2Vec or FastText).\n",
        "     2. **Segment Embeddings**: Used to distinguish between two sentences in the same input (important for Next Sentence Prediction tasks).\n",
        "     3. **Positional Embeddings**: Provide information about the position of each word in the input sequence.\n",
        "   - The final input representation for each token is the **sum of these three embeddings.**\n",
        "\n",
        "### **2.3 Example: BERT Embeddings**\n",
        "Suppose we have the input sentence:\n",
        "> \"The cat sat on the mat.\"\n",
        "\n",
        "**Input Processing**:\n",
        "1. **Token Embeddings**: BERT will convert each word into a dense vector (e.g., \"The\" -> [0.25, 0.45, ...], \"cat\" -> [0.33, 0.67, ...]).\n",
        "2. **Positional Embeddings**: Each token gets an additional embedding based on its position in the sentence (e.g., \"The\" gets the position 0 embedding, \"cat\" gets position 1).\n",
        "3. **Segment Embeddings**: If this were part of a pair of sentences, we could assign different embeddings to tokens from different sentences (e.g., \"Sentence A\" vs. \"Sentence B\").\n",
        "\n",
        "**Combined Representation**:\n",
        "- For the word **\"cat,\"** the final input embedding will be the sum of **Token + Positional + Segment** embeddings.\n",
        "\n",
        "### **2.4 Why BERT is Effective for Complex Contexts**\n",
        "1. **Bidirectional Self-Attention**:\n",
        "   - Because BERT is **bidirectional**, it can understand context based on both preceding and succeeding words. This is crucial for understanding complex sentence structures and nuanced meanings.\n",
        "   - For example, BERT can distinguish between **\"bank\"** in \"river bank\" and \"financial bank\" because it reads the whole sentence.\n",
        "\n",
        "2. **Contextual Word Embeddings**:\n",
        "   - Unlike traditional word embeddings that are static (e.g., Word2Vec always has the same vector for \"bank\"), BERT generates **dynamic, context-aware embeddings**. The embedding for \"bank\" will be different depending on whether it's in the context of \"money\" or \"river.\"\n",
        "   - This makes BERT very powerful for tasks where subtle differences in meaning are important.\n",
        "\n",
        "### **2.5 Use Cases of BERT**\n",
        "1. **Text Classification**: Sentiment analysis, spam detection, topic categorization.\n",
        "2. **Question Answering**: Given a passage and a question, BERT can find the answer in the passage.\n",
        "3. **Named Entity Recognition (NER)**: Identifying entities like names, places, and dates in text.\n",
        "4. **Text Summarization**: Extracting key information from long texts.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "s9WaPwpyn2oO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4PGRpWIon4I_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT Architecture"
      ],
      "metadata": {
        "id": "mWHiMCsFoZhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great! Now let's move on to **GPT-based models** and understand how they utilize the **Decoder** part of the Transformer architecture, focusing on how they differ from BERT.\n",
        "\n",
        "### **3. GPT-Based Models (Generative Pre-trained Transformer)**\n",
        "\n",
        "**GPT (Generative Pre-trained Transformer)** models, introduced by OpenAI, are designed primarily for **text generation** tasks. Unlike BERT, which uses the Encoder from the Transformer architecture to understand and process input, **GPT relies on the Decoder** to generate coherent and contextually appropriate text.\n",
        "\n",
        "### **3.1 Key Differences Between BERT and GPT**\n",
        "1. **Architecture Usage**:\n",
        "   - **BERT**: Uses the **Encoder** part of the Transformer. It is mainly focused on understanding language, making it effective for tasks like classification, question answering, and named entity recognition (NER).\n",
        "   - **GPT**: Uses the **Decoder** part of the Transformer. It is primarily designed for **generative tasks** like text completion, conversation, and creative writing.\n",
        "\n",
        "2. **Directionality**:\n",
        "   - **BERT is Bidirectional**: It reads the entire sequence of words simultaneously, considering the context from both left and right (past and future words). This helps it understand complex dependencies.\n",
        "   - **GPT is Unidirectional**: It reads the text from **left to right**. This means GPT generates text by predicting the next word in the sequence based only on the words it has already seen (left context). This makes it ideal for generative tasks where the model needs to create coherent sequences word by word.\n",
        "\n",
        "3. **Training Objective**:\n",
        "   - **BERT**: Pre-trained on two tasks—**Masked Language Modeling (MLM)** (predicting masked words in a sentence) and **Next Sentence Prediction (NSP)** (understanding sentence relationships).\n",
        "   - **GPT**: Pre-trained using a **causal language modeling (CLM)** objective, where it learns to predict the next word in a sequence. This trains it to generate fluent, coherent text that follows naturally from the context.\n",
        "\n",
        "### **3.2 How GPT Works**\n",
        "**The GPT model architecture** is a stack of **Decoder layers** from the Transformer, each layer containing:\n",
        "1. **Masked Self-Attention**:\n",
        "   - Similar to the Decoder in the original Transformer, GPT uses **Masked Self-Attention**, meaning that while predicting a word, it only considers the previous words (left-to-right context). This mask prevents it from seeing future words, ensuring that it generates text in a coherent, sequential manner.\n",
        "2. **Feed-Forward Neural Network (FFN)**:\n",
        "   - After the attention mechanism, the outputs are passed through an FFN, which helps the model learn complex transformations and patterns.\n",
        "3. **Residual Connections and Layer Normalization**:\n",
        "   - Like in the Encoder, each layer in GPT includes residual connections and layer normalization to stabilize the training process.\n",
        "\n",
        "### **3.3 Example: Text Generation with GPT**\n",
        "Let’s look at how GPT might generate text:\n",
        "Suppose we have the prompt:\n",
        "> \"The sun was setting over the horizon, casting a warm glow over the...\"\n",
        "\n",
        "1. **Step 1: Input Processing**:\n",
        "   - The input (\"The sun was setting over the horizon, casting a warm glow over the\") is tokenized and passed through the GPT model.\n",
        "2. **Step 2: Masked Self-Attention**:\n",
        "   - GPT reads each word from left to right and learns which words should come next based on the attention mechanism. For instance, it might focus on **\"setting\"** and **\"horizon\"** to understand that the next word could be something related to **\"sky\"** or **\"landscape.\"**\n",
        "3. **Step 3: Word Generation**:\n",
        "   - The model predicts the next word based on the previous context, such as **\"ocean.\"** It then appends **\"ocean\"** to the input and repeats the process to generate the following word. This continues until it generates a complete sentence or paragraph.\n",
        "\n",
        "### **3.4 GPT Variants and Evolution**\n",
        "1. **GPT-1**: The original model that introduced the concept of using the Decoder architecture for generative tasks. It was a proof-of-concept that demonstrated how effective pre-training could be for language generation.\n",
        "2. **GPT-2**: A larger and more powerful version of GPT-1. It could generate coherent and contextually appropriate paragraphs of text, leading to impressive (and sometimes surprising) results. GPT-2 was **pre-trained on 1.5 billion parameters**.\n",
        "3. **GPT-3**: The most famous version, capable of performing tasks like **translation, summarization, code generation, and conversation**. It has **175 billion parameters**, making it significantly more powerful than its predecessors. GPT-3 can perform tasks it hasn’t been explicitly trained for through a technique called **few-shot learning**, where it learns from just a few examples provided at inference time.\n",
        "\n",
        "### **3.5 Use Cases of GPT Models**\n",
        "1. **Text Completion**: Given a prompt, GPT can generate a continuation of the text, making it useful for creative writing, marketing copy, and storytelling.\n",
        "2. **Conversation/Chatbots**: GPT can maintain context over a conversation, making it effective for creating more natural chatbots.\n",
        "3. **Content Creation**: Writing articles, summaries, and even poetry.\n",
        "4. **Code Generation**: Generating code snippets based on a description (like GitHub Copilot).\n",
        "5. **Translation**: Translating text from one language to another.\n",
        "\n",
        "### **3.6 Limitations of GPT Models**\n",
        "1. **Lack of True Understanding**: While GPT can generate coherent text, it doesn’t truly understand the meaning. It’s pattern-based and can sometimes produce **misleading or nonsensical** content if the input is ambiguous.\n",
        "2. **Bias and Ethical Concerns**: Since GPT is trained on vast amounts of internet data, it can inadvertently learn and reproduce **biases** present in that data. This has led to discussions about the ethical implications of deploying such models.\n",
        "3. **No Bidirectional Context**: Unlike BERT, which can consider both past and future context, GPT only reads left-to-right, which might limit its performance in tasks that require a deeper understanding of the entire sentence.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "1dCXy5S6odMV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GZNiS6sEofTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tune BERT"
      ],
      "metadata": {
        "id": "j59U4nG0otjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# wandb api-key (to be pasted below): 77d5e6061e08428a2172dead53787acbd14bfe6b\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from transformers import logging\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Step 1: Preprocess the Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# Step 2: Load and Preprocess the Dataset\n",
        "file_path = 'data_mental_health.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop unnecessary columns if any (e.g., index column)\n",
        "df_cleaned = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "\n",
        "# Convert target labels to numeric\n",
        "df_cleaned['class'] = df_cleaned['class'].apply(lambda x: 1 if x == 'suicide' else 0)\n",
        "\n",
        "# Tokenizer for BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Prepare Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_cleaned['text'], df_cleaned['class'], test_size=0.2, random_state=42)\n",
        "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer, max_len=128)\n",
        "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer, max_len=128)\n",
        "\n",
        "# Step 3: Load Pre-Trained BERT Model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Define Evaluation Metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Step 4: Fine-Tune the Model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=2,  # Keep this low for notebook runtime\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the Model\n",
        "eval_result = trainer.evaluate()\n",
        "print(f\"Evaluation Result: {eval_result}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1503731486ad447aad818bcfce2f9f99",
            "f83c81b821424328b4985d3ee56c2a1e",
            "6a60f039478c46e6ac15b2f6841bad66",
            "120dc89d1bd44596b8948fc199122f59",
            "cd4361fdf90748d49c0294b65b672f8f",
            "228f542ecc0149fa99d13a25c933ecfc",
            "367549f9315443babb85e13f55df98bf",
            "7b0389e4eec649369f34c4346fb38102",
            "db929e5d6d4e4b41a56b558f1bca2809",
            "325fdf865369439ea03d97f1b2edb2bd",
            "b88ff76de8ba48f791d816275b14f811",
            "5babb6add5c14a97aea2db33258d62a1",
            "66e32fd496684d2e88ba0d9673f5c42a",
            "bc73e5e739a749ee90bb01e73c9f4a23",
            "b86b95d5308b41b5b404db002ca1ba74",
            "820ed39bdc26444bbff5ed418f905848",
            "e5a2925490124d4dab752353dbb59561",
            "10f9b094166d4f66a0fccb3afca2bcf9",
            "675536c9214b478f813cfe653c59aa16",
            "ff97af07bd3649a8bf28e27a7a90ae13",
            "485fd7265b03432dbaa568cfd1e2f6d2",
            "9a986585bd1049e18f3b8abf8f980387",
            "9b7e42d8e8ef4f508b3d3577c18a157e",
            "f76726fc81d44e1bac1c2dc476d369a6",
            "1b6cc79106d548e08c67f2ec7a58418e",
            "166f285b921d41d99e802e60c2196efb",
            "bd331553b91f4a6995a09c1713e5e841",
            "5c49f6f5e0054e2b94e4d984874af284",
            "3f08e1220f92441b9fcbaef5e967ab1b",
            "2241ccaa2f4c4da2ada33bbd84bf8a2f",
            "c1bc3facf77147e0b66f844e11312b20",
            "8a260d900ef54db1878fb5a131f5a9bc",
            "368d13e1ad2f4fc485e97d46383485d8",
            "18daf77dd72e45d9a1b019924a84280c",
            "592187af9dfb4e75a5573dcd62f4c707",
            "dc0b099cf67443e2b55ec5beae3a2bc8",
            "795c4aaa8ad14323b7d2171387d3312f",
            "dd923a002e75454bab960e945c7bfdbb",
            "2b23237207044cc5bda7a84d0492593a",
            "359881f863f04b52b2ce9689d856f50f",
            "1e5ffdeb4bd64d5d86c35920cb5b9a85",
            "eece52f0f1f74741900817a3ae6df0a6",
            "048623baa20c4c1483cd2771061e0398",
            "1989f05c35a341ec9c1af5dd9031559f",
            "355039680b53439faf9161bee31dfc3c",
            "1fba630d0be747aabc03329c6627026a",
            "2002bfd68a28428ab71544d987d36e2b",
            "bc4fdf8aebf14780b3645a5e82b02f15",
            "f0fd5c0fb0ec4ed08fc952311b1dacc4",
            "228a59c42c62405c80db8ea076de4b66",
            "02f35f8298b54290b7a0840ac8ca7bd0",
            "49bbfbcaca114dae94202bc01a2e43bd",
            "5d3301358f054f3896a69cc00ca45eef",
            "09f4d3feb2d04bbba1d4704c03346184",
            "9ac425f6dd5444788c4ced7529712e86"
          ]
        },
        "id": "IjISZHOxovIZ",
        "outputId": "229e7962-4c18-45b5-d899-2904beb5a66d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1503731486ad447aad818bcfce2f9f99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5babb6add5c14a97aea2db33258d62a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b7e42d8e8ef4f508b3d3577c18a157e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18daf77dd72e45d9a1b019924a84280c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "355039680b53439faf9161bee31dfc3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241026_210516-l6btr53g</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/srivineet93-university-of-illinois-chicago/huggingface/runs/l6btr53g' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/srivineet93-university-of-illinois-chicago/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/srivineet93-university-of-illinois-chicago/huggingface' target=\"_blank\">https://wandb.ai/srivineet93-university-of-illinois-chicago/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/srivineet93-university-of-illinois-chicago/huggingface/runs/l6btr53g' target=\"_blank\">https://wandb.ai/srivineet93-university-of-illinois-chicago/huggingface/runs/l6btr53g</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 04:18, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.259483</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.928862</td>\n",
              "      <td>0.906746</td>\n",
              "      <td>0.952083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.111700</td>\n",
              "      <td>0.227430</td>\n",
              "      <td>0.949000</td>\n",
              "      <td>0.947150</td>\n",
              "      <td>0.942268</td>\n",
              "      <td>0.952083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Result: {'eval_loss': 0.22743020951747894, 'eval_accuracy': 0.949, 'eval_f1': 0.9471502590673575, 'eval_precision': 0.9422680412371134, 'eval_recall': 0.9520833333333333, 'eval_runtime': 9.0137, 'eval_samples_per_second': 110.942, 'eval_steps_per_second': 13.868, 'epoch': 2.0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7647153e98c4>\u001b[0m in \u001b[0;36m<cell line: 125>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0mnormal_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"I’ve been dealing with depression for a few years now, and it hasn’t been easy. There were times when I felt like giving up, but I found strength in seeking help. Therapy and talking to friends really made a difference. Now, I’m in a much better place, and I want to use my experience to support others who might be going through something similar. Mental health is so important, and I believe we need to talk about it openly. If sharing my story can encourage even one person to seek help, then it’s worth it.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tricky Example Prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtricky_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Normal Example Prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormal_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-7647153e98c4>\u001b[0m in \u001b[0;36mpredict_text\u001b[0;34m(text, tokenizer, model, max_len)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mpredicted_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1696\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m         embedding_output = self.embeddings(\n\u001b[0m\u001b[1;32m   1078\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2549\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text, tokenizer, model, max_len=128):\n",
        "    # Check the device of the model (it will be on GPU if available)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Tokenize and prepare input\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt',\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)  # Move input to the same device\n",
        "    attention_mask = encoding['attention_mask'].to(device)  # Move input to the same device\n",
        "\n",
        "    # Predict using the model\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        predicted_class = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    return \"Suicide\" if predicted_class == 1 else \"Non-Suicide\"\n"
      ],
      "metadata": {
        "id": "pEIjkkmeo236"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tricky_text = \"Lately, I’ve been struggling a lot. There are days when I feel completely overwhelmed, like everything is crashing down around me, and I just want to escape. But then there are moments where I think maybe things could get better, that I might find a way through this. I’ve been trying to reach out to friends, and they’ve been supportive, but it’s hard to explain what I’m going through. Some days are okay, but other days, the darkness just feels too heavy to bear. I wish I could see a light at the end of the tunnel, but it’s not always there. I just don’t know what to do anymore.\"\n",
        "\n",
        "normal_text = \"I’ve been dealing with depression for a few years now, and it hasn’t been easy. There were times when I felt like giving up, but I found strength in seeking help. Therapy and talking to friends really made a difference. Now, I’m in a much better place, and I want to use my experience to support others who might be going through something similar. Mental health is so important, and I believe we need to talk about it openly. If sharing my story can encourage even one person to seek help, then it’s worth it.\"\n",
        "\n",
        "print(\"Tricky Example Prediction:\", predict_text(tricky_text, tokenizer, model))\n",
        "print(\"Normal Example Prediction:\", predict_text(normal_text, tokenizer, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPUoo71_reEg",
        "outputId": "89c044df-15ec-4594-f036-abc5ec48e94a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tricky Example Prediction: Suicide\n",
            "Normal Example Prediction: Suicide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Step 1: Preprocess the Dataset\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.samples = []\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "        for text, label in zip(texts, labels):\n",
        "            # Tokenize the text and get token IDs\n",
        "            tokenized_text = self.tokenizer.encode(text, add_special_tokens=True)\n",
        "            # Split the tokenized text into chunks\n",
        "            for i in range(0, len(tokenized_text), self.max_len - 2):  # Reserve space for special tokens\n",
        "                chunk = tokenized_text[i:i + self.max_len - 2]\n",
        "                # Add special tokens\n",
        "                chunk = [self.tokenizer.cls_token_id] + chunk + [self.tokenizer.sep_token_id]\n",
        "                # Pad if necessary\n",
        "                padding_length = self.max_len - len(chunk)\n",
        "                attention_mask = [1] * len(chunk) + [0] * padding_length\n",
        "                chunk += [self.tokenizer.pad_token_id] * padding_length\n",
        "                self.samples.append({\n",
        "                    'input_ids': torch.tensor(chunk, dtype=torch.long),\n",
        "                    'attention_mask': torch.tensor(attention_mask, dtype=torch.long),\n",
        "                    'labels': torch.tensor(label, dtype=torch.long)\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.samples[idx]\n",
        "\n",
        "\n",
        "# Step 2: Load and Preprocess the Dataset\n",
        "file_path = 'data_mental_health.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Drop unnecessary columns if any (e.g., index column)\n",
        "df_cleaned = df.drop(columns=['Unnamed: 0'], errors='ignore')\n",
        "\n",
        "# Convert target labels to numeric\n",
        "df_cleaned['class'] = df_cleaned['class'].apply(lambda x: 1 if x == 'suicide' else 0)\n",
        "\n",
        "# Tokenizer for BERT\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Prepare Dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_cleaned['text'], df_cleaned['class'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Set max sequence length to 512\n",
        "max_len = 512\n",
        "\n",
        "# Update dataset creation\n",
        "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer, max_len=max_len)\n",
        "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer, max_len=max_len)\n",
        "\n",
        "\n",
        "# Step 3: Compute Class Weights\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "# Step 4: Load Pre-Trained BERT Model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model.to(device)\n",
        "\n",
        "# Define Evaluation Metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average='binary', zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "# Custom Trainer to include class weights\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, class_weights, *args, **kwargs):\n",
        "        super(WeightedTrainer, self).__init__(*args, **kwargs)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\").to(device)\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        # compute custom loss\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
        "        loss = loss_fct(\n",
        "            logits.view(-1, self.model.config.num_labels),\n",
        "            labels.view(-1)\n",
        "        )\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Step 5: Fine-Tune the Model\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=10,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    seed=42  # Set seed for reproducibility\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    class_weights=class_weights\n",
        ")\n",
        "\n",
        "# Train the Model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the Model\n",
        "eval_result = trainer.evaluate()\n",
        "print(f\"Evaluation Result: {eval_result}\")\n",
        "\n",
        "def predict_text(text, tokenizer, model, max_len=128):\n",
        "    # Tokenize the text and get token IDs\n",
        "    tokenized_text = tokenizer.encode(text, add_special_tokens=True)\n",
        "    logits_list = []\n",
        "\n",
        "    # Split into chunks\n",
        "    for i in range(0, len(tokenized_text), max_len - 2):  # Reserve space for special tokens\n",
        "        chunk = tokenized_text[i:i + max_len - 2]\n",
        "        # Add special tokens\n",
        "        chunk = [tokenizer.cls_token_id] + chunk + [tokenizer.sep_token_id]\n",
        "        # Pad if necessary\n",
        "        padding_length = max_len - len(chunk)\n",
        "        attention_mask = [1] * len(chunk) + [0] * padding_length\n",
        "        chunk += [tokenizer.pad_token_id] * padding_length\n",
        "\n",
        "        input_ids = torch.tensor([chunk], dtype=torch.long).to(device)\n",
        "        attention_mask = torch.tensor([attention_mask], dtype=torch.long).to(device)\n",
        "\n",
        "        # Predict using the model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            logits_list.append(logits)\n",
        "\n",
        "    # Aggregate logits\n",
        "    aggregated_logits = torch.sum(torch.stack(logits_list), dim=0)\n",
        "    predicted_class = torch.argmax(aggregated_logits, dim=1).item()\n",
        "\n",
        "    return \"Suicide\" if predicted_class == 1 else \"Non-Suicide\"\n",
        "\n",
        "\n",
        "# Test Texts\n",
        "tricky_text = \"Lately, I’ve been struggling a lot. There are days when I feel completely overwhelmed, like everything is crashing down around me, and I just want to escape. But then there are moments where I think maybe things could get better, that I might find a way through this. I’ve been trying to reach out to friends, and they’ve been supportive, but it’s hard to explain what I’m going through. Some days are okay, but other days, the darkness just feels too heavy to bear. I wish I could see a light at the end of the tunnel, but it’s not always there. I just don’t know what to do anymore.\"\n",
        "\n",
        "normal_text = \"I’ve been dealing with depression for a few years now, and it hasn’t been easy. There were times when I felt like giving up, but I found strength in seeking help. Therapy and talking to friends really made a difference. Now, I’m in a much better place, and I want to use my experience to support others who might be going through something similar. Mental health is so important, and I believe we need to talk about it openly. If sharing my story can encourage even one person to seek help, then it’s worth it.\"\n",
        "\n",
        "# Predictions\n",
        "print(\"Tricky Example Prediction:\", predict_text(tricky_text, tokenizer, model))\n",
        "print(\"Normal Example Prediction:\", predict_text(normal_text, tokenizer, model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "WHAHyFJBsR-s",
        "outputId": "f344fca9-a240-4ad1-fdb7-4147310a7120"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (573 > 512). Running this sequence through the model will result in indexing errors\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1632' max='1632' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1632/1632 22:51, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.370600</td>\n",
              "      <td>0.184729</td>\n",
              "      <td>0.934579</td>\n",
              "      <td>0.931774</td>\n",
              "      <td>0.983539</td>\n",
              "      <td>0.885185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.232448</td>\n",
              "      <td>0.943925</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.944444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.208562</td>\n",
              "      <td>0.952336</td>\n",
              "      <td>0.953082</td>\n",
              "      <td>0.946984</td>\n",
              "      <td>0.959259</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='134' max='134' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [134/134 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Result: {'eval_loss': 0.20856234431266785, 'eval_accuracy': 0.9523364485981308, 'eval_f1': 0.953081876724931, 'eval_precision': 0.946983546617916, 'eval_recall': 0.9592592592592593, 'eval_runtime': 31.5315, 'eval_samples_per_second': 33.934, 'eval_steps_per_second': 4.25, 'epoch': 3.0}\n",
            "Tricky Example Prediction: Suicide\n",
            "Normal Example Prediction: Suicide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "THE3jgHU0JFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text, tokenizer, model, max_len=128):\n",
        "    # Tokenize the text and get token IDs\n",
        "    tokenized_text = tokenizer.encode(text, add_special_tokens=True)\n",
        "    logits_list = []\n",
        "\n",
        "    # Split into chunks\n",
        "    for i in range(0, len(tokenized_text), max_len - 2):  # Reserve space for special tokens\n",
        "        chunk = tokenized_text[i:i + max_len - 2]\n",
        "        # Add special tokens\n",
        "        chunk = [tokenizer.cls_token_id] + chunk + [tokenizer.sep_token_id]\n",
        "        # Pad if necessary\n",
        "        padding_length = max_len - len(chunk)\n",
        "        attention_mask = [1] * len(chunk) + [0] * padding_length\n",
        "        chunk += [tokenizer.pad_token_id] * padding_length\n",
        "\n",
        "        input_ids = torch.tensor([chunk], dtype=torch.long).to(device)\n",
        "        attention_mask = torch.tensor([attention_mask], dtype=torch.long).to(device)\n",
        "\n",
        "        # Predict using the model\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            logits_list.append(logits)\n",
        "\n",
        "    # Aggregate logits\n",
        "    aggregated_logits = torch.sum(torch.stack(logits_list), dim=0)\n",
        "    predicted_class = torch.argmax(aggregated_logits, dim=1).item()\n",
        "\n",
        "    return \"Suicide\" if predicted_class == 1 else \"Non-Suicide\"\n",
        "\n",
        "\n",
        "# Test Texts\n",
        "tricky_text = \"Lately, I’ve been struggling a lot. There are days when I feel completely overwhelmed, like everything is crashing down around me, and I just want to escape. But then there are moments where I think maybe things could get better, that I might find a way through this. I’ve been trying to reach out to friends, and they’ve been supportive, but it’s hard to explain what I’m going through. Some days are okay, but other days, the darkness just feels too heavy to bear. I wish I could see a light at the end of the tunnel, but it’s not always there. I just don’t know what to do anymore.\"\n",
        "\n",
        "normal_text = \"I want to use my experience to support others who might be going through something similar, and I believe we need to talk about it openly. If sharing my story can encourage even one person to seek help, then it’s worth it.\"\n",
        "\n",
        "# Predictions\n",
        "print(\"Tricky Example Prediction:\", predict_text(tricky_text, tokenizer, model))\n",
        "print(\"Normal Example Prediction:\", predict_text(normal_text, tokenizer, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLJ8_bba0JIN",
        "outputId": "5f2fcd79-580e-4201-c15a-fc92fea83317"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tricky Example Prediction: Suicide\n",
            "Normal Example Prediction: Suicide\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MgBJ-B4n0JLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGQ4sh_L0JNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GamepEL_vw0Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}